{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "DATA_DIR = Path('data')\n",
    "OUT_DIR = Path('processed')\n",
    "OUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "climate_files = [\n",
    "    'Huye_climate_data.csv','Kigali_climate_data.csv','Muhanga_climate_data.csv',\n",
    "    'Kibungo_climate_data.csv','Musanze_climate_data.csv','Nyagatare_climate_data.csv',\n",
    "    'Rubavu_climate_data.csv','Rusizi_climate_data.csv'\n",
    "]\n",
    "\n",
    "climate_dfs = {}\n",
    "for f in climate_files:\n",
    "    loc = f.split('_')[0].lower()\n",
    "    df = pd.read_csv(DATA_DIR / f, parse_dates=['Date'], na_values=['-999.0', -999.0])\n",
    "    df.replace(-999.0, np.nan, inplace=True)\n",
    "    climate_dfs[loc] = df\n",
    "\n",
    "tomato = pd.read_csv(DATA_DIR / 'Tomato_price.csv', parse_dates=['Date'])\n",
    "harvest = pd.read_csv(DATA_DIR / 'harvest_dataset.csv', parse_dates=['Date'])\n",
    "\n",
    "print(f\"Loaded {len(climate_dfs)} climate datasets, tomato: {tomato.shape}, harvest: {harvest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATA CLEANING\n",
    "missing_before = sum(df.isnull().sum().sum() for df in climate_dfs.values()) + tomato.isnull().sum().sum() + harvest.isnull().sum().sum()\n",
    "duplicates_before = sum(df.duplicated().sum() for df in climate_dfs.values()) + tomato.duplicated().sum() + harvest.duplicated().sum()\n",
    "\n",
    "# Clean climate data\n",
    "for loc, df in climate_dfs.items():\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    for col in df.select_dtypes(include='number').columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Clean tomato and harvest\n",
    "tomato.drop_duplicates(inplace=True)\n",
    "tomato['Average'] = pd.to_numeric(tomato['Average'], errors='coerce')\n",
    "tomato['Average'] = tomato['Average'].fillna(tomato['Average'].median())\n",
    "\n",
    "harvest.drop_duplicates(inplace=True)\n",
    "harvest['Date'] = pd.to_datetime(harvest['Date']).dt.tz_localize(None)\n",
    "for col in harvest.select_dtypes(include='number').columns:\n",
    "    harvest[col] = harvest[col].fillna(harvest[col].median())\n",
    "\n",
    "missing_after = sum(df.isnull().sum().sum() for df in climate_dfs.values()) + tomato.isnull().sum().sum() + harvest.isnull().sum().sum()\n",
    "duplicates_after = sum(df.duplicated().sum() for df in climate_dfs.values()) + tomato.duplicated().sum() + harvest.duplicated().sum()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(['Before', 'After'], [missing_before, missing_after])\n",
    "plt.title('Missing Values Before vs After Cleaning')\n",
    "plt.ylabel('Total Missing Values')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(['Before', 'After'], [duplicates_before, duplicates_after])\n",
    "plt.title('Duplicate Rows Before vs After Cleaning')\n",
    "plt.ylabel('Total Duplicates')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATA INTEGRATION\n",
    "# Rename and aggregate climate data\n",
    "for loc, df in climate_dfs.items():\n",
    "    df.rename(columns={'T2M':'temp_c','PRECTOTCORR':'precip_mm','WS2M':'wind_m_s','RH2M':'rh_pct','ALLSKY_SFC_SW_DWN':'sw_down'}, inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.normalize()\n",
    "    climate_dfs[loc] = df.groupby('Date').agg({'temp_c':'mean','precip_mm':'sum','wind_m_s':'mean','rh_pct':'mean','sw_down':'mean'}).reset_index()\n",
    "\n",
    "# Merge all climate stations\n",
    "all_daily = [df.rename(columns=lambda c: f\"{loc}_{c}\" if c!='Date' else c) for loc, df in climate_dfs.items()]\n",
    "climate_all = reduce(lambda a,b: a.merge(b,on='Date',how='outer'), all_daily)\n",
    "\n",
    "temp_cols = [c for c in climate_all.columns if c.endswith('temp_c')]\n",
    "precip_cols = [c for c in climate_all.columns if c.endswith('precip_mm')]\n",
    "wind_cols = [c for c in climate_all.columns if c.endswith('wind_m_s')]\n",
    "rh_cols = [c for c in climate_all.columns if c.endswith('rh_pct')]\n",
    "\n",
    "climate_avg = pd.DataFrame({\n",
    "    'Date': climate_all['Date'],\n",
    "    'temp_c': climate_all[temp_cols].mean(axis=1),\n",
    "    'precip_mm': climate_all[precip_cols].sum(axis=1),\n",
    "    'wind_m_s': climate_all[wind_cols].mean(axis=1),\n",
    "    'rh_pct': climate_all[rh_cols].mean(axis=1)\n",
    "}).drop_duplicates(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Clean and merge tomato data\n",
    "tomato.rename(columns={'Average':'price_avg'}, inplace=True)\n",
    "tomato['Date'] = pd.to_datetime(tomato['Date']).dt.normalize()\n",
    "\n",
    "# Merge harvest data\n",
    "harvest_daily = harvest.groupby('Date').agg({'Harvest_kg':'sum','Price_index':'mean'}).reset_index()\n",
    "\n",
    "# Final integration\n",
    "integrated_df = tomato.merge(climate_avg, on='Date', how='left').merge(harvest_daily, on='Date', how='left')\n",
    "integrated_df[['Harvest_kg','Price_index']] = integrated_df[['Harvest_kg','Price_index']].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(['Climate', 'Tomato', 'Harvest', 'Integrated'], [len(climate_avg), len(tomato), len(harvest_daily), len(integrated_df)])\n",
    "plt.title('Records in Each Dataset Before vs After Integration')\n",
    "plt.ylabel('Records')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Integrated dataset shape: {integrated_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DATA REDUCTION\n",
    "reduce_cols = ['Date', 'price_avg', 'temp_c', 'precip_mm', 'wind_m_s', 'rh_pct', 'Harvest_kg', 'Price_index']\n",
    "reduced_df = integrated_df[reduce_cols].copy()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(['Before', 'After'], [integrated_df.shape[1], reduced_df.shape[1]])\n",
    "plt.title('Number of Columns Before vs After Reduction')\n",
    "plt.ylabel('Columns')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Reduced from {integrated_df.shape[1]} to {reduced_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DATA TRANSFORMATION\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = ['price_avg', 'temp_c', 'precip_mm', 'wind_m_s', 'rh_pct', 'Harvest_kg', 'Price_index']\n",
    "reduced_df[numeric_cols] = scaler.fit_transform(reduced_df[numeric_cols])\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(integrated_df['price_avg'].dropna(), kde=True, color='gray', label='Before')\n",
    "plt.legend()\n",
    "plt.title('Price Distribution Before Scaling')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(reduced_df['price_avg'], kde=True, color='blue', label='After')\n",
    "plt.legend()\n",
    "plt.title('Price Distribution After Scaling')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DATA DISCRETIZATION\n",
    "reduced_df['temp_category'] = pd.cut(reduced_df['temp_c'], bins=3, labels=['Cool', 'Moderate', 'Warm'])\n",
    "reduced_df['precip_category'] = pd.cut(reduced_df['precip_mm'], bins=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=reduced_df['temp_category'], palette='coolwarm')\n",
    "plt.title('Temperature Categories After Discretization')\n",
    "plt.ylabel('Records')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=reduced_df['precip_category'], palette='Blues')\n",
    "plt.title('Precipitation Categories After Discretization')\n",
    "plt.ylabel('Records')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. DATA AUGMENTATION\n",
    "augmented = reduced_df.sample(frac=0.1, random_state=42)\n",
    "augmented[numeric_cols] += np.random.normal(0, 0.05, size=(augmented.shape[0], len(numeric_cols)))\n",
    "augmented['source'] = 'Synthetic'\n",
    "reduced_df['source'] = 'Original'\n",
    "augmented_df = pd.concat([reduced_df, augmented], ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(['Before', 'After'], [reduced_df.shape[0], augmented_df.shape[0]])\n",
    "plt.title('Dataset Size Before vs After Augmentation')\n",
    "plt.ylabel('Records')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final dataset shape: {augmented_df.shape}\")\n",
    "print(f\"Original records: {(augmented_df['source'] == 'Original').sum()}\")\n",
    "print(f\"Synthetic records: {(augmented_df['source'] == 'Synthetic').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "augmented_df.to_csv(OUT_DIR / 'processed_farmer_data.csv', index=False)\n",
    "print(f\"Processed data saved to {OUT_DIR / 'processed_farmer_data.csv'}\")\n",
    "print(\"\\nFinal dataset summary:\")\n",
    "print(augmented_df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(augmented_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}